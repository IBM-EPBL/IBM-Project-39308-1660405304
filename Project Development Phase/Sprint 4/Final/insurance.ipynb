{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9Wv1yc1LCXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530b3db3-192f-4d2f-8a00-7db7fce26899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 62 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.14.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.38.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (2.1.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 67.4 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 61.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.50.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.21.6)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.2.5\n",
            "  Downloading Keras-2.2.5-py2.py3-none-any.whl (336 kB)\n",
            "\u001b[K     |████████████████████████████████| 336 kB 34.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (6.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.7.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.5) (1.5.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "Successfully installed keras-2.2.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mrcnn\n",
            "  Downloading mrcnn-0.2.tar.gz (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 286 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mrcnn\n",
            "  Building wheel for mrcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mrcnn: filename=mrcnn-0.2-py3-none-any.whl size=54932 sha256=fcf243c5379601e1a7dfc449913e9bdeaa1632770fea4fb1a9fa6b8492316f4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/94/0d/03ff96abc43d2d6c8299a92cbb4eced2a1eda3ca7911c19427\n",
            "Successfully built mrcnn\n",
            "Installing collected packages: mrcnn\n",
            "Successfully installed mrcnn-0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 40.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.14\n",
        "!pip install keras==2.2.5\n",
        "!pip install mrcnn\n",
        "!pip install h5py==2.10.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "import cv2\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from shapely.geometry import Polygon\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "from mrcnn.visualize import display_instances\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JABS-_wEOmOC",
        "outputId": "0e108646-9a07-4403-dc2e-cf332f204c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "_sFVA7GOOnGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "ROOT_DIR = '/content/drive/MyDrive/pythoncode/insuranceApp'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRsM0iE0Or7C",
        "outputId": "f131ac50-6883-4826-b3d2-9efc21600498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "WEIGHTS_PATH = \"/content/drive/MyDrive/pythoncode/insuranceApp/logs/object20221106T0743/mask_rcnn_object_0011.h5\""
      ],
      "metadata": {
        "id": "1GPhSbZ8Ou7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomConfig(Config):\n",
        "\n",
        "    NAME = \"object\"\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    NUM_CLASSES = 1 + 2\n",
        "    STEPS_PER_EPOCH = 50\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9"
      ],
      "metadata": {
        "id": "N2DEreS9PgRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(utils.Dataset):\n",
        "    def load_custom(self, dataset_dir, subset):\n",
        "\n",
        "        self.add_class(\"object\", 1, \"scratch\")\n",
        "        self.add_class(\"object\", 2, \"dent\")\n",
        "        \n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        dataset_dir = os.path.join(dataset_dir + subset)\n",
        "\n",
        "        annotations1 = json.load(open(os.path.join(dataset_dir + '/' + \"via_region_data_json.json\"),'r',encoding=\"utf8\",errors='ignore'))\n",
        "        annotations = list(annotations1.values())\n",
        "\n",
        "        annotations = [a for a in annotations if a['regions']]\n",
        "        \n",
        "        for a in annotations:\n",
        "            \n",
        "            polygons = [r['shape_attributes'] for r in a['regions']]\n",
        "            objects = [s['region_attributes']['name'] for s in a['regions']]\n",
        "            print(\"objects: \",objects)\n",
        "            name_dict = {\"scratch\": 1, \"dent\": 2}\n",
        "\n",
        "            num_ids = [name_dict[a] for a in objects]\n",
        "\n",
        "            print(\"numids\", num_ids)\n",
        "\n",
        "            image_path = os.path.join(dataset_dir, a['filename'])\n",
        "            image = skimage.io.imread(image_path)\n",
        "            height, width = image.shape[:2]\n",
        "\n",
        "            self.add_image(\n",
        "                \"object\",\n",
        "                image_id=a['filename'],\n",
        "                path=image_path,\n",
        "                width=width, height=height,\n",
        "                polygons=polygons,\n",
        "                num_ids=num_ids)\n",
        "            \n",
        "    def load_mask(self, image_id):\n",
        "        \n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"object\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "        \n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] != \"object\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "        num_ids = info['num_ids']\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            mask[rr, cc, i] = 1\n",
        "\n",
        "        num_ids = np.array(num_ids, dtype=np.int32)\n",
        "        return mask, num_ids\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"object\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)"
      ],
      "metadata": {
        "id": "IQw-Y-uNPvLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_MODE = \"inference\"\n",
        "\n",
        "def get_ax(rows=1, cols=1, size=16):    \n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "metadata": {
        "id": "Nc9li4f8P0SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhyD2mdg8uiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOM_DIR = \"/content/drive/MyDrive/pythoncode/insuranceApp/dataset/\"\n",
        "dataset = CustomDataset()\n",
        "dataset.load_custom(CUSTOM_DIR, \"val\")\n",
        "dataset.prepare()\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
      ],
      "metadata": {
        "id": "JBTRyT-fkFjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e6cc23-0ce3-40d4-b77e-77dee8259167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objects:  ['scratch', 'scratch', 'scratch']\n",
            "numids [1, 1, 1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch', 'scratch']\n",
            "numids [1, 1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch', 'scratch']\n",
            "numids [1, 1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent', 'scratch', 'dent']\n",
            "numids [2, 1, 2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent', 'scratch']\n",
            "numids [2, 1]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent', 'dent']\n",
            "numids [2, 2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "Images: 36\n",
            "Classes: ['BG', 'scratch', 'dent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "config = CustomConfig()\n",
        "#LOAD MODEL. Create model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsq82GKTQ-2p",
        "outputId": "c19a8d63-36ba-450b-b5af-8d796413cc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:723: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:725: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:775: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load COCO weights Or, load the last model you trained\n",
        "weights_path = WEIGHTS_PATH\n",
        "# Load weights\n",
        "print(\"Loading weights \", weights_path)\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJf9cxHYRN1B",
        "outputId": "92e22013-8176-4e86-9c34-60820cd7082d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights  /content/drive/MyDrive/pythoncode/insuranceApp/logs/object20221106T0743/mask_rcnn_object_0011.h5\n",
            "Re-starting from epoch 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
        "\n",
        "# This is for predicting images which are not present in dataset\n",
        "path_to_new_image = '/content/drive/MyDrive/pythoncode/insuranceApp/dataset/test/test3.jpg'\n",
        "image1 = mpimg.imread(path_to_new_image)\n",
        "\n",
        "# Run object detection\n",
        "#print(len([image1]))\n",
        "results1 = model.detect([image1], verbose=0)\n",
        "\n",
        "\n",
        "# Display results\n",
        "ax = get_ax(1)\n",
        "r1 = results1[0]\n",
        "\n",
        "def save_co_ordinates(image, boxes, masks, class_ids, class_names):\n",
        "    image = image.split(\"/\")[-1]\n",
        "    image_data = []\n",
        "\n",
        "    for i in range(boxes.shape[0]):\n",
        "\n",
        "        # class_id = class_ids[i]\n",
        "        # label = class_names[class_id]\n",
        "\n",
        "        mask = masks[:, :, i]\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            list_co_ordinates = np.moveaxis(verts, 1, 0).tolist()\n",
        "\n",
        "            region = {\"shape_attributes\": {\"all_points_x\": list_co_ordinates[0],\n",
        "                                           \"all_points_y\": list_co_ordinates[1]},\n",
        "                      }\n",
        "            image_data.append(region)\n",
        "    data = {\"filename\": image, \"regions\": image_data, \"count\": boxes.shape[0]}\n",
        "    return data\n",
        "\n",
        "data = save_co_ordinates(path_to_new_image, r1['rois'], r1['masks'], r1['class_ids'], ['scratch','dent'])\n",
        "\n",
        "for i in range(data['count']):\n",
        "  x = data['regions'][i]['shape_attributes']['all_points_x']\n",
        "  y = data['regions'][i]['shape_attributes']['all_points_y']\n",
        "  pgon = Polygon(zip(x, y))\n",
        "  print(pgon.area)\n",
        "\n",
        "print(data['count'])\n",
        "\n",
        "visualize.display_instances(image1, r1['rois'], r1['masks'], r1['class_ids'],\n",
        "dataset.class_names, r1['scores'], ax=ax, title=\"Predictions1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "UEhR0h1KRQpv",
        "outputId": "2dce8138-55cb-4047-cc72-8a096ff0a557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-51d17873ec92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This is for predicting images which are not present in dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath_to_new_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/pythoncode/insuranceApp/dataset/test/test3.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_new_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Run object detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mpimg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pycocotools import mask"
      ],
      "metadata": {
        "id": "2EXVevtSpRUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from skimage import measure"
      ],
      "metadata": {
        "id": "i2i0KSyjpsJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9VXjn8GTr4nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c67TQlgBvqqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaR5z6DRrwMd",
        "outputId": "3f0edf85-5fa6-47f9-f9db-52e43dd4af82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9599.5\n",
            "10.5\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shapely"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw2KDnE9vfTl",
        "outputId": "55fc7890-d7ad-4249-b5f9-65a199dcefd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (1.8.5.post1)\n"
          ]
        }
      ]
    }
  ]
}