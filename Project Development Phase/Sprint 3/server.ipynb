{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejmc3WhvGVrG",
        "outputId": "fc9daba4-c4f8-4624-94b9-131cdcb6d2f8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n"
          ]
        }
      ],
      "source": [
        "######Step 1########\n",
        "\n",
        "!pip install flask-ngrok\n",
        "!pip install tensorflow==1.14\n",
        "!pip install keras==2.2.5\n",
        "!pip install mrcnn\n",
        "!pip install h5py==2.10.0\n",
        "!pip install ibm_db\n",
        "!pip install shapely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV1GB9NXB3Vl"
      },
      "outputs": [],
      "source": [
        "####Visualize.py changes######\n",
        "######Step 2 - Copy and paste into mrcnn.visualizer##########\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def save_image(image, image_name, boxes, masks, class_ids, scores, class_names, filter_classs_names=None,\n",
        "               scores_thresh=0.1, save_dir=None, mode=0):\n",
        "    \n",
        "    mode_list = [0, 1, 2, 3]\n",
        "    assert mode in mode_list, \"mode's value should in mode_list %s\" % str(mode_list)\n",
        "\n",
        "    useful_mask_indices = []\n",
        "\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances in image %s to draw *** \\n\" % (image_name))\n",
        "        return\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    for i in range(N):\n",
        "        class_id = class_ids[i]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        if score is None or score < scores_thresh:\n",
        "            continue\n",
        "\n",
        "        label = class_names[class_id]\n",
        "        if (filter_classs_names is not None) and (label not in filter_classs_names):\n",
        "            continue\n",
        "\n",
        "        if not np.any(boxes[i]):\n",
        "            continue\n",
        "\n",
        "        useful_mask_indices.append(i)\n",
        "\n",
        "    if len(useful_mask_indices) == 0:\n",
        "        print(\"\\n*** No instances in image %s to draw *** \\n\" % (image_name))\n",
        "        return\n",
        "\n",
        "    colors = random_colors(len(useful_mask_indices))\n",
        "\n",
        "    if mode != 3:\n",
        "        masked_image = image.astype(np.uint8).copy()\n",
        "    else:\n",
        "        masked_image = np.zeros(image.shape).astype(np.uint8)\n",
        "\n",
        "    if mode != 1:\n",
        "        for index, value in enumerate(useful_mask_indices):\n",
        "            masked_image = apply_mask(masked_image, masks[:, :, value], colors[index])\n",
        "\n",
        "    masked_image = Image.fromarray(masked_image)\n",
        "\n",
        "    if mode == 3:\n",
        "        masked_image.save(os.path.join(image_name))\n",
        "        return\n",
        "\n",
        "    draw = ImageDraw.Draw(masked_image)\n",
        "    colors = np.array(colors).astype(int) * 255\n",
        "\n",
        "    for index, value in enumerate(useful_mask_indices):\n",
        "        class_id = class_ids[value]\n",
        "        score = scores[value]\n",
        "        label = class_names[class_id]\n",
        "\n",
        "        y1, x1, y2, x2 = boxes[value]\n",
        "        if mode != 2:\n",
        "            color = tuple(colors[index])\n",
        "            draw.rectangle((x1, y1, x2, y2), outline=color)\n",
        "\n",
        "        draw.text((x1, y1), \"%s %f\" % (label, score), (255, 255, 255))\n",
        "\n",
        "    masked_image.save(os.path.join(image_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLs_zlGKzHdu",
        "outputId": "14f0e3ed-3296-4005-d255-43d6d39e19ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "###Step-3#####\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "import cv2\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from shapely.geometry import Polygon\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.visualize import save_image\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "import uuid\n",
        "import base64\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,request,jsonify,request,send_from_directory\n",
        "\n",
        "import ibm_db\n",
        "\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jDJaW5eb_4h",
        "outputId": "5de07e0d-be5c-41b7-f840-db22a08fdcdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive/')\n",
        "ROOT_DIR = '/content/drive/MyDrive/insuranceApp'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T5Kigdq0GEV"
      },
      "outputs": [],
      "source": [
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "WEIGHTS_PATH = \"/content/drive/MyDrive/insuranceApp/logs/object20221106T0743/mask_rcnn_object_0011.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9eyc6Mc0LP1"
      },
      "outputs": [],
      "source": [
        "class CustomConfig(Config):\n",
        "\n",
        "    NAME = \"object\"\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    NUM_CLASSES = 1 + 2\n",
        "    STEPS_PER_EPOCH = 50\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1oFVVqu0gBd"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(utils.Dataset):\n",
        "    def load_custom(self, dataset_dir, subset):\n",
        "\n",
        "        self.add_class(\"object\", 1, \"scratch\")\n",
        "        self.add_class(\"object\", 2, \"dent\")\n",
        "        \n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        dataset_dir = os.path.join(dataset_dir + subset)\n",
        "\n",
        "        annotations1 = json.load(open(os.path.join(dataset_dir + '/' + \"via_region_data_json.json\"),'r',encoding=\"utf8\",errors='ignore'))\n",
        "        annotations = list(annotations1.values())\n",
        "\n",
        "        annotations = [a for a in annotations if a['regions']]\n",
        "        \n",
        "        for a in annotations:\n",
        "            \n",
        "            polygons = [r['shape_attributes'] for r in a['regions']]\n",
        "            objects = [s['region_attributes']['name'] for s in a['regions']]\n",
        "            print(\"objects: \",objects)\n",
        "            name_dict = {\"scratch\": 1, \"dent\": 2}\n",
        "\n",
        "            num_ids = [name_dict[a] for a in objects]\n",
        "\n",
        "            print(\"numids\", num_ids)\n",
        "\n",
        "            image_path = os.path.join(dataset_dir, a['filename'])\n",
        "            image = skimage.io.imread(image_path)\n",
        "            height, width = image.shape[:2]\n",
        "\n",
        "            self.add_image(\n",
        "                \"object\",\n",
        "                image_id=a['filename'],\n",
        "                path=image_path,\n",
        "                width=width, height=height,\n",
        "                polygons=polygons,\n",
        "                num_ids=num_ids)\n",
        "            \n",
        "    def load_mask(self, image_id):\n",
        "        \n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"object\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "        \n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] != \"object\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "        num_ids = info['num_ids']\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            mask[rr, cc, i] = 1\n",
        "\n",
        "        num_ids = np.array(num_ids, dtype=np.int32)\n",
        "        return mask, num_ids\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"object\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpXhoXkW0caY"
      },
      "outputs": [],
      "source": [
        "TEST_MODE = \"inference\"\n",
        "\n",
        "def get_ax(rows=1, cols=1, size=16):    \n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4xeXb5T0ivV",
        "outputId": "09eaa4f4-91e6-4425-d751-d3bcc6ba4c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objects:  ['scratch', 'scratch', 'scratch']\n",
            "numids [1, 1, 1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch', 'scratch']\n",
            "numids [1, 1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch', 'scratch']\n",
            "numids [1, 1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent', 'scratch', 'dent']\n",
            "numids [2, 1, 2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent', 'scratch']\n",
            "numids [2, 1]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['scratch']\n",
            "numids [1]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent', 'dent']\n",
            "numids [2, 2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n",
            "objects:  ['dent']\n",
            "numids [2]\n"
          ]
        }
      ],
      "source": [
        "CUSTOM_DIR = \"/content/drive/MyDrive/insuranceApp/dataset/\"\n",
        "dataset = CustomDataset()\n",
        "dataset.load_custom(CUSTOM_DIR, \"val\")\n",
        "dataset.prepare()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYkO1YfP0l2x",
        "outputId": "700f95f5-52e2-401a-938f-d37147ac47ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:723: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:725: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/mrcnn/model.py:775: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ]
        }
      ],
      "source": [
        "config = CustomConfig()\n",
        "#LOAD MODEL. Create model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SR4mugr0pmK",
        "outputId": "6b61f27f-92d8-4772-e50a-f36a72d3b525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading weights  /content/drive/MyDrive/insuranceApp/logs/object20221106T0743/mask_rcnn_object_0011.h5\n",
            "Re-starting from epoch 11\n"
          ]
        }
      ],
      "source": [
        "# Load COCO weights Or, load the last model you trained\n",
        "weights_path = WEIGHTS_PATH\n",
        "# Load weights\n",
        "print(\"Loading weights \", weights_path)\n",
        "model.load_weights(weights_path, by_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2pCiRJ40wKx"
      },
      "outputs": [],
      "source": [
        "def prediction(uid,filename):\n",
        "  # print(uid)\n",
        "  area = 0\n",
        "  # path_to_new_image = '/content/drive/MyDrive/pythoncode/insuranceApp/dataset/test/test3.jpg'\n",
        "  path_to_new_image = os.path.join(ROOT_DIR + '/server/public/' + uid +'/'+ filename)\n",
        "  print(path_to_new_image)\n",
        "  image1 = mpimg.imread(path_to_new_image)\n",
        "  print(np.shape(image1.shape))\n",
        "  if np.shape(image1.shape)[0] < 3:\n",
        "    image1 = image1.reshape((*image1.shape, 1))\n",
        "\n",
        "  # Run object detection\n",
        "  #print(len([image1]))\n",
        "  results1 = model.detect([image1], verbose=0)\n",
        "\n",
        "\n",
        "  # Display results\n",
        "  # ax = get_ax(1)\n",
        "  r1 = results1[0]\n",
        "\n",
        "  def save_co_ordinates(image, boxes, masks, class_ids, class_names):\n",
        "      image = image.split(\"/\")[-1]\n",
        "      image_data = []\n",
        "\n",
        "      for i in range(boxes.shape[0]):\n",
        "\n",
        "          mask = masks[:, :, i]\n",
        "          padded_mask = np.zeros(\n",
        "              (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "          padded_mask[1:-1, 1:-1] = mask\n",
        "          contours = find_contours(padded_mask, 0.5)\n",
        "          for verts in contours:\n",
        "              verts = np.fliplr(verts) - 1\n",
        "              list_co_ordinates = np.moveaxis(verts, 1, 0).tolist()\n",
        "\n",
        "              region = {\"shape_attributes\": {\"all_points_x\": list_co_ordinates[0],\n",
        "                                            \"all_points_y\": list_co_ordinates[1]},\n",
        "                        }\n",
        "              image_data.append(region)\n",
        "      data = {\"filename\": image, \"regions\": image_data, \"count\": boxes.shape[0]}\n",
        "      return data\n",
        "\n",
        "  data = save_co_ordinates(path_to_new_image, r1['rois'], r1['masks'], r1['class_ids'], ['scratch','dent'])\n",
        "\n",
        "  for i in range(data['count']):\n",
        "    x = data['regions'][i]['shape_attributes']['all_points_x']\n",
        "    y = data['regions'][i]['shape_attributes']['all_points_y']\n",
        "    pgon = Polygon(zip(x, y))\n",
        "    area = pgon.area + area\n",
        "    print(pgon.area)\n",
        "\n",
        "  print(data['count'])\n",
        "\n",
        "  ##############################################################\n",
        "\n",
        "  visualize.save_image(image1, path_to_new_image, r1['rois'], r1['masks'],\n",
        "    r1['class_ids'],r1['scores'],dataset.class_names,\n",
        "    filter_classs_names=['scratch', 'dent'],scores_thresh=0.9,mode=0)\n",
        "\n",
        "  ###########################################################################\n",
        "\n",
        "  return round(area,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYmLM0KRSln3"
      },
      "outputs": [],
      "source": [
        "# prediction('2cbd9bd1','2cbd9bd1_1.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJUUCwYNGsYy",
        "outputId": "c866a431-f56a-4fea-d539-a2a726127176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: ngrok: command not found\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken \"2H8eWbGDXW4viF60odCrATxzFyY_6d2KvavAHc1K9JbK6xRGw\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGsBruQaV8dv"
      },
      "outputs": [],
      "source": [
        "dsn_hostname = \"ba99a9e6-d59e-4883-8fc0-d6a8c9f7a08f.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud\"\n",
        "dsn_uid = \"hzh82386\"\n",
        "dsn_pwd = \"oTey9hQKSeDethjI\"\n",
        "\n",
        "dsn_driver = \"{IBM DB2 ODBC DRIVER}\"\n",
        "dsn_database = \"BLUDB\"\n",
        "dsn_port = \"31321\" \n",
        "dsn_protocol = \"TCPIP\"\n",
        "dsn_security = \"SSL\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsJaCeGtV_yx",
        "outputId": "498503d2-5803-4bfb-9a8b-2e96cdefa7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DRIVER={IBM DB2 ODBC DRIVER};DATABASE=BLUDB;HOSTNAME=ba99a9e6-d59e-4883-8fc0-d6a8c9f7a08f.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud;PORT=31321;PROTOCOL=TCPIP;UID=hzh82386;PWD=oTey9hQKSeDethjI;SECURITY=SSL;\n"
          ]
        }
      ],
      "source": [
        "dsn = (\n",
        "    \"DRIVER={0};\"\n",
        "    \"DATABASE={1};\"\n",
        "    \"HOSTNAME={2};\"\n",
        "    \"PORT={3};\"\n",
        "    \"PROTOCOL={4};\"\n",
        "    \"UID={5};\"\n",
        "    \"PWD={6};\"\n",
        "    \"SECURITY={7};\").format(dsn_driver, dsn_database, dsn_hostname, dsn_port, dsn_protocol, dsn_uid, dsn_pwd,dsn_security)\n",
        "\n",
        "print(dsn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwDs0aFGWCHb",
        "outputId": "4157d236-a9c4-411f-fbc1-549c27084bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to database:  BLUDB as user:  hzh82386 on host:  ba99a9e6-d59e-4883-8fc0-d6a8c9f7a08f.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    conn = ibm_db.connect(dsn, \"\", \"\")\n",
        "    print (\"Connected to database: \", dsn_database, \"as user: \", dsn_uid, \"on host: \", dsn_hostname)\n",
        "\n",
        "except:\n",
        "    print (\"Unable to connect: \", ibm_db.conn_errormsg())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyHTZPsjWLIs",
        "outputId": "45785de2-3e36-4b2a-9f71-e7f79e3d5c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# sql_stmt = \"CREATE TABLE users (Uid varchar(255), Username varchar(255), Password varchar(255), carName varchar(255), regNo varchar(255), regDate varchar(255), claimAmount varchar(255))\"\n",
        "# stmt = ibm_db.prepare(conn, sql_stmt)\n",
        "\n",
        "# try:\n",
        "#     resp = ibm_db.execute(stmt)    \n",
        "#     print(resp)\n",
        "# except:\n",
        "#     print(ibm_db.stmt_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOp-XLW3WEH1",
        "outputId": "b625bc57-5a92-427b-d2a0-b03d66df244d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# sql_stmt = \"CREATE TABLE images (Uid varchar(255), Result varchar(255), Amount varchar(255))\"\n",
        "# stmt = ibm_db.prepare(conn, sql_stmt)\n",
        "\n",
        "# try:\n",
        "#     resp = ibm_db.execute(stmt)    \n",
        "#     print(resp)\n",
        "# except:\n",
        "#     print(ibm_db.stmt_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqK1cucqGUTQ",
        "outputId": "0ceb9f07-3f23-4456-f4bd-2b1c1658c65b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://d8a4-34-125-183-117.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2022 09:02:55] \"\u001b[37mPOST /login?username=sss&password=1111 HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<ibm_db.IBM_DBStatement object at 0x7fec4aa23ce0>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2022 09:02:57] \"\u001b[37mPOST /getImage?uid=2cbd9bd1 HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['2cbd9bd1_1.jpg', '2cbd9bd1_2.jpg', '2cbd9bd1_3.jpg', '2cbd9bd1_4.jpg']\n",
            "<ibm_db.IBM_DBStatement object at 0x7fec4aa23d50>\n",
            "True\n",
            "[{'filename': '2cbd9bd1_1.jpg', 'area': '751.7575', 'amount': '150351.5'}, {'filename': '2cbd9bd1_2.jpg', 'area': '62.0565', 'amount': '12411.3'}, {'filename': '2cbd9bd1_3.jpg', 'area': '31.2505', 'amount': '6250.1'}, {'filename': '2cbd9bd1_4.jpg', 'area': '1.1885', 'amount': '237.7'}]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2022 09:03:01] \"\u001b[37mGET /viewImage?uid=2cbd9bd1&filename=2cbd9bd1_1.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2022 09:03:01] \"\u001b[37mGET /viewImage?uid=2cbd9bd1&filename=2cbd9bd1_4.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2022 09:03:01] \"\u001b[37mGET /viewImage?uid=2cbd9bd1&filename=2cbd9bd1_2.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2022 09:03:01] \"\u001b[37mGET /viewImage?uid=2cbd9bd1&filename=2cbd9bd1_3.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2022 09:47:56] \"\u001b[37mPOST /getImage?uid= HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "<ibm_db.IBM_DBStatement object at 0x7fec4aa23ea0>\n",
            "True\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   \n",
        "  \n",
        "@app.route('/register', methods = ['POST','GET'])\n",
        "def signUp():\n",
        "    username = request.args.get('username')\n",
        "    carName = request.args.get('carName')\n",
        "    regNo = request.args.get('regNo')\n",
        "    regDate = request.args.get('regDate')\n",
        "    password = request.args.get('password')\n",
        "\n",
        "    sql_stmt = \"INSERT INTO users VALUES(?,?,?,?,?,?,?)\"\n",
        "    stmt = ibm_db.prepare(conn, sql_stmt)\n",
        "    uid = uuid.uuid4().hex[:8]\n",
        "    ibm_db.bind_param(stmt, 1, uid)\n",
        "    ibm_db.bind_param(stmt, 2, username)\n",
        "    ibm_db.bind_param(stmt, 3, password)\n",
        "    ibm_db.bind_param(stmt, 4, carName)\n",
        "    ibm_db.bind_param(stmt, 5, regNo)\n",
        "    ibm_db.bind_param(stmt, 6, regDate)\n",
        "    ibm_db.bind_param(stmt, 7, \"\")\n",
        "\n",
        "    try:\n",
        "        resp = ibm_db.execute(stmt)    \n",
        "        if resp:\n",
        "            try:\n",
        "                resp = jsonify({\"success\": uid})\n",
        "                resp.headers.add('Access-Control-Allow-Origin', '*')\n",
        "                return resp\n",
        "            except:\n",
        "                resp = jsonify({\"success\": False})\n",
        "                resp.headers.add('Access-Control-Allow-Origin', '*')\n",
        "                return resp\n",
        "                \n",
        "    except:\n",
        "        print(ibm_db.stmt_error)\n",
        "\n",
        "@app.route('/login', methods = ['POST','GET'])\n",
        "def signIn():\n",
        "\n",
        "    username = request.args.get('username')\n",
        "    password = request.args.get('password')\n",
        "\n",
        "    sql_stmt = f\"SELECT * FROM users WHERE Username='{username}' AND Password='{password}'\"\n",
        "    stmt = ibm_db.prepare(conn, sql_stmt)\n",
        "\n",
        "    print(stmt)\n",
        "\n",
        "    try:\n",
        "        resp = ibm_db.execute(stmt)         \n",
        "        row = ibm_db.fetch_both(stmt)\n",
        "        if row == False:\n",
        "            resp = jsonify({\"uid\":False})\n",
        "            resp.headers.add('Access-Control-Allow-Origin', '*')\n",
        "            return resp           \n",
        "        else:\n",
        "            listData = {\n",
        "              \"uid\": row['UID'],\n",
        "              \"username\": row['USERNAME'],\n",
        "              \"carname\": row['CARNAME'],\n",
        "              \"regno\": row['REGNO'],\n",
        "              \"regdate\": row['REGDATE'],\n",
        "              \"claim\": row['CLAIMAMOUNT']\n",
        "            }\n",
        "            resp = jsonify(listData)\n",
        "            resp.headers.add('Access-Control-Allow-Origin', '*')\n",
        "            return resp\n",
        "               \n",
        "    except:\n",
        "        print(ibm_db.stmt_error)\n",
        "\n",
        "@app.route('/postImage', methods = ['POST'])\n",
        "def setImg():\n",
        "    \n",
        "    index = 1    \n",
        "    # print(request.form)\n",
        "    data = request.form\n",
        "    vals = list(data.values())\n",
        "    vals.pop(0)\n",
        "\n",
        "    analyzed = []\n",
        "    insertValues = []\n",
        "    claimAmount = 0\n",
        "    \n",
        "\n",
        "    if not os.path.exists(ROOT_DIR + '/server/public/' + data['uid']):\n",
        "        os.makedirs(ROOT_DIR + '/server/public/' + data['uid'])\n",
        "\n",
        "    for x in vals:\n",
        "        fileName = data['uid']+'_'+str(index)\n",
        "\n",
        "        with open(ROOT_DIR + '/server/public/' + data['uid'] + '/' + fileName + \".jpg\", \"wb\") as f:\n",
        "            f.write(base64.decodebytes(str.encode(x)))\n",
        "\n",
        "        index += 1\n",
        "\n",
        "    onlyfiles = [f for f in listdir(ROOT_DIR + '/server/public/'+data['uid']+'/') if isfile(join(ROOT_DIR + '/server/public/'+data['uid']+'/', f))]\n",
        "\n",
        "    print(onlyfiles)\n",
        "\n",
        "    # prediction(data['uid'],onlyfiles[0])\n",
        "    # prediction('das231564a','das231564a_1.jpg')\n",
        "\n",
        "    # time.sleep(20)\n",
        "    \n",
        "\n",
        "    for x in onlyfiles:\n",
        "      listData = {\n",
        "        \"filename\": str(x),\n",
        "        \"area\": \"\",\n",
        "        \"amount\": 0\n",
        "      }\n",
        "      # tmpData = {\n",
        "      #     \"filename\": str(x),\n",
        "      #     \"area\": \"\",\n",
        "      #     \"amount\": 0\n",
        "      # }\n",
        "      result = prediction(str(data['uid']),str(x))\n",
        "      print(x)\n",
        "      listData['area'] = (result / 1000)\n",
        "      listData['amount'] = round((listData['area'] * 200),2)\n",
        "      claimAmount += listData['amount']\n",
        "      analyzed.append(listData)\n",
        "      insertValues.append((data['uid'],str(listData['area']),str(listData['amount'])))\n",
        "    print(analyzed)\n",
        "    print(insertValues)\n",
        "\n",
        "    tuple_of_tuples = tuple([tuple(x) for x in insertValues])\n",
        "\n",
        "    sql_stmt = f\"INSERT INTO images VALUES(?,?,?)\"\n",
        "    stmt = ibm_db.prepare(conn, sql_stmt)\n",
        "\n",
        "    try:\n",
        "        exe = ibm_db.execute_many(stmt,tuple_of_tuples)    \n",
        "        print(exe)    \n",
        "        sql_stmt_2 = f\"update users set claimamount='{str(claimAmount)}' where uid='{data['uid']}'\"\n",
        "        res = ibm_db.exec_immediate(conn, sql_stmt_2)\n",
        "        resp = jsonify(analyzed)\n",
        "        resp.headers.add('Access-Control-Allow-Origin', '*')\n",
        "        return resp\n",
        "    except:\n",
        "        resp = jsonify({\"uid\": 'error'})\n",
        "        resp.headers.add('Access-Control-Allow-Origin', '*')\n",
        "        return resp\n",
        "        print(ibm_db.stmt_error)\n",
        "    \n",
        "\n",
        "\n",
        "@app.route('/viewImage', methods = ['POST','GET'])\n",
        "def viewImg():\n",
        "    uid = request.args['uid']\n",
        "    filename = request.args['filename']\n",
        "    # uid = request.args['uid']    \n",
        "    # print(list(uid))\n",
        "    return send_from_directory(ROOT_DIR + '/server/public/'+uid+'/', filename)\n",
        "\n",
        "@app.route('/getImage', methods = ['POST'])\n",
        "def getImg():\n",
        "    uid = request.args['uid']\n",
        "    imageData = []\n",
        "    fileCount = 0\n",
        "    onlyfiles = [f for f in listdir(ROOT_DIR + '/server/public/'+uid+'/') if isfile(join(ROOT_DIR + '/server/public/'+uid+'/', f))]\n",
        "    print(onlyfiles)\n",
        "    sql_stmt = f\"SELECT * FROM images WHERE uid='{uid}'\"\n",
        "    stmt = ibm_db.prepare(conn, sql_stmt)\n",
        "\n",
        "    print(stmt)\n",
        "\n",
        "    try:\n",
        "        exe = ibm_db.execute(stmt)    \n",
        "        print(exe)\n",
        "        row = ibm_db.fetch_both(stmt)\n",
        "        while(row):\n",
        "            listData = {\n",
        "                \"filename\": str(onlyfiles[fileCount]),\n",
        "                \"area\": row[1],\n",
        "                \"amount\": row[2]\n",
        "            }\n",
        "            imageData.append(listData)\n",
        "            fileCount += 1\n",
        "            # print(row[0])\n",
        "            # print()\n",
        "            # print()\n",
        "            row = ibm_db.fetch_both(stmt)\n",
        "        print(imageData)\n",
        "        resp = jsonify(imageData)\n",
        "        resp.headers.add('Access-Control-Allow-Origin', '*')\n",
        "        return resp\n",
        "        \n",
        "    except:\n",
        "        print(ibm_db.stmt_error)\n",
        "    \n",
        "app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDOuEHDQXZBf",
        "outputId": "af26bd99-0de9-4f65-c0a2-a312efd43a82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ibm_db.close(conn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}